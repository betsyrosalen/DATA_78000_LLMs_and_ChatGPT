# Some thoughts on Bias and Toxicity in Large Language Models

While I think it's a noble and necessary goal to strive to remove bias and toxicity from large laguage models like ChatGPT, I think that ultimately it may prove impossible. At the very least it may be a never-ending iterative process as future generations look at systems created with the biases of our time from a new future perspective that we couldn't possibly anticipate today. That's not to say we shouldn't try and do as much as we can to work toward that goal, but if we keep in mind that they are systems created by human beings, embedded within a particular time period, and that they are based on data sets created by human beings, during particular historic or current times, then I don't think that we, as human beings, can reasonably expect to be capable of removing all of our own biases from these systems. Everything we create will be impacted by the standpoint of it's creators, and although we can try to implement data feminism or design justice principles and practices into the development of these systems, there will always be someone whose viewpoint is left ouf of that process. No matter how much curating we do to those data sets or how many rules we add to their constitutions, there will always be cases (even if only "edge" cases) where we failed to see our own comscious or unconscious biases. Think for example of the people who may think that these systems shouldn't even be created in the first place. The fact that many of use see them as inevitable is an outcome of our own technological bias.

Given the possibility that the task is not feasible, I think we should also be striving to ensure that the way we *use* those systems is as much as possible for the public good. The famous line from Spider-Man comics applies here: "With great power comes great responsibility." This too may be an ultimately unachievable goal, but it certainly won't happen if we don't make a conscious and concerted effort to ensure that things move in that direction. Even the tech sector and AI experts agree that the potential power of AI is like nothing we have seen before so it follows that this kind of power should not be in the hands of power-hungry and money-hungry organizations whether they be corporations or governments. If AI makes good on its techno-utopian promise and takes over the tedious and laborious tasks that most humans don't want to do anyway, then we need to make sure that we have social systems in place to help those whose jobs are automated or eliminated.  