{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51f17aa",
   "metadata": {},
   "source": [
    "## Ngrams lab\n",
    "LLM's and ChatGPT | Fall 2023 | McSweeney | CUNY Graduate Center\n",
    "\n",
    "**Due:** September 17\n",
    "\n",
    "\n",
    "### Background\n",
    "The purpose of this lab is to explore ngram models. Ngram models are a good introduction to language models generally. Language models are probabilistic representations of language. Ngrams have the benefit of being easy to interrogate and relatively easy to understand (as compared to neural networks). \n",
    "\n",
    "In this lab, you will build an ngram model from the corpus of your choosing. The example is with 'The Great Gatsby' from Project Gutenberg, but there's a code block for any text file on your computer  \n",
    "\n",
    "\n",
    "#### Notes\n",
    "This lab is based heavily on the [nltk documentation](https://www.nltk.org/api/nltk.lm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ef35858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "# if you haven't downloaded punkt before, you only need to run the line below once \n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "from nltk.util import bigrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b881ad5b",
   "metadata": {},
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7017636",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "An example of how ngrams are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "de8054bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of The War of the Worlds        This ebook is for the use of anyone any\n"
     ]
    }
   ],
   "source": [
    "# you will need to leverage the requests package\n",
    "r = requests.get(r'https://www.gutenberg.org/cache/epub/36/pg36.txt')\n",
    "war_ot_worlds = r.text\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    war_ot_worlds = war_ot_worlds.replace(char, \" \")\n",
    "\n",
    "# check\n",
    "print(war_ot_worlds[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "886ac257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK ONE  THE COMING OF THE MARTIANS          I.  THE EVE OF THE WAR.      No one would have believed in the last years of the nineteenth century  tha\n"
     ]
    }
   ],
   "source": [
    "# remove the metadata at the beginning - this is slightly different for each book\n",
    "war_ot_worlds = war_ot_worlds[1928:]\n",
    "print(war_ot_worlds[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f37081c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361520\n"
     ]
    }
   ],
   "source": [
    "print(len(war_ot_worlds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "fceebd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  *** END OF THE PROJECT GUTENBERG EBOOK THE WAR OF THE WORLDS ***                      Updated editions will replace the previous one—the old editions will  be renamed.    Creating the works from print editions not protected by U.S. copyright  law means that no one owns a United States copyright in these works,  so the Foundation (and you!) can copy and distribute it in the United  States without permission and without paying copyright  royalties. Special rules, set forth in the General Terms of Use part  of this license, apply to copying and distributing Project  Gutenberg™ electronic works to protect the PROJECT GUTENBERG™  concept and trademark. Project Gutenberg is a registered trademark,  and may not be used if you charge for an eBook, except by following  the terms of the trademark license, including paying royalties for use  of the Project Gutenberg trademark. If you do not charge anything for  copies of this eBook, complying with the trademark license is very  easy. You may use this eBook for nearly any purpose such as creation  of derivative works, reports, performances and research. Project  Gutenberg eBooks may be modified and printed and given away—you may  do practically ANYTHING in the United States with eBooks not protected  by U.S. copyright law. Redistribution is subject to the trademark  license, especially commercial redistribution.      START: FULL LICENSE    THE FULL PROJECT GUTENBERG LICENSE    PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK    To protect the Project Gutenberg™ mission of promoting the free  distribution of electronic works, by using or distributing this work  (or any other work associated in any way with the phrase “Project  Gutenberg”), you agree to comply with all the terms of the Full  Project Gutenberg™ License available with this file or online at  www.gutenberg.org/license.    Section 1. General Terms of Use and Redistributing Project Gutenberg™  electronic works    1.A. By reading or using any part of this Project Gutenberg™  electronic work, you indicate that you have read, understand, agree to  and accept all the terms of this license and intellectual property  (trademark/copyright) agreement. If you do not agree to abide by all  the terms of this agreement, you must cease using and return or  destroy all copies of Project Gutenberg™ electronic works in your  possession. If you paid a fee for obtaining a copy of or access to a  Project Gutenberg™ electronic work and you do not agree to be bound  by the terms of this agreement, you may obtain a refund from the person  or entity to whom you paid the fee as set forth in paragraph 1.E.8.    1.B. “Project Gutenberg” is a registered trademark. It may only be  used on or associated in any way with an electronic work by people who  agree to be bound by the terms of this agreement. There are a few  things that you can do with most Project Gutenberg™ electronic works  even without complying with the full terms of this agreement. See  paragraph 1.C below. There are a lot of things you can do with Project  Gutenberg™ electronic works if you follow the terms of this  agreement and help preserve free future access to Project Gutenberg™  electronic works. See paragraph 1.E below.    1.C. The Project Gutenberg Literary Archive Foundation (“the  Foundation” or PGLAF), owns a compilation copyright in the collection  of Project Gutenberg™ electronic works. Nearly all the individual  works in the collection are in the public domain in the United  States. If an individual work is unprotected by copyright law in the  United States and you are located in the United States, we do not  claim a right to prevent you from copying, distributing, performing,  displaying or creating derivative works based on the work as long as  all references to Project Gutenberg are removed. Of course, we hope  that you will support the Project Gutenberg™ mission of promoting  free access to electronic works by freely sharing Project Gutenberg™  works in compliance with the terms of this agreement for keeping the  Project Gutenberg™ name associated with the work. You can easily  comply with the terms of this agreement by keeping this work in the  same format with its attached full Project Gutenberg™ License when  you share it without charge with others.    1.D. The copyright laws of the place where you are located also govern  what you can do with this work. Copyright laws in most countries are  in a constant state of change. If you are outside the United States,  check the laws of your country in addition to the terms of this  agreement before downloading, copying, displaying, performing,  distributing or creating derivative works based on this work or any  other Project Gutenberg™ work. The Foundation makes no  representations concerning the copyright status of any work in any  country other than the United States.    1.E. Unless you have removed all references to Project Gutenberg:    1.E.1. The following sentence, with active links to, or other  immediate access to, the full Project Gutenberg™ License must appear  prominently whenever any copy of a Project Gutenberg™ work (any work  on which the phrase “Project Gutenberg” appears, or with which the  phrase “Project Gutenberg” is associated) is accessed, displayed,  performed, viewed, copied or distributed:        This eBook is for the use of anyone anywhere in the United States and most      other parts of the world at no cost and with almost no restrictions      whatsoever. You may copy it, give it away or re-use it under the terms      of the Project Gutenberg License included with this eBook or online      at www.gutenberg.org. If you      are not located in the United States, you will have to check the laws      of the country where you are located before using this eBook.      1.E.2. If an individual Project Gutenberg™ electronic work is  derived from texts not protected by U.S. copyright law (does not  contain a notice indicating that it is posted with permission of the  copyright holder), the work can be copied and distributed to anyone in  the United States without paying any fees or charges. If you are  redistributing or providing access to a work with the phrase “Project  Gutenberg” associated with or appearing on the work, you must comply  either with the requirements of paragraphs 1.E.1 through 1.E.7 or  obtain permission for the use of the work and the Project Gutenberg™  trademark as set forth in paragraphs 1.E.8 or 1.E.9.    1.E.3. If an individual Project Gutenberg™ electronic work is posted  with the permission of the copyright holder, your use and distribution  must comply with both paragraphs 1.E.1 through 1.E.7 and any  additional terms imposed by the copyright holder. Additional terms  will be linked to the Project Gutenberg™ License for all works  posted with the permission of the copyright holder found at the  beginning of this work.    1.E.4. Do not unlink or detach or remove the full Project Gutenberg™  License terms from this work, or any files containing a part of this  work or any other work associated with Project Gutenberg™.    1.E.5. Do not copy, display, perform, distribute or redistribute this  electronic work, or any part of this electronic work, without  prominently displaying the sentence set forth in paragraph 1.E.1 with  active links or immediate access to the full terms of the Project  Gutenberg™ License.    1.E.6. You may convert to and distribute this work in any binary,  compressed, marked up, nonproprietary or proprietary form, including  any word processing or hypertext form. However, if you provide access  to or distribute copies of a Project Gutenberg™ work in a format  other than “Plain Vanilla ASCII” or other format used in the official  version posted on the official Project Gutenberg™ website  (www.gutenberg.org), you must, at no additional cost, fee or expense  to the user, provide a copy, a means of exporting a copy, or a means  of obtaining a copy upon request, of the work in its original “Plain  Vanilla ASCII” or other form. Any alternate format must include the  full Project Gutenberg™ License as specified in paragraph 1.E.1.    1.E.7. Do not charge a fee for access to, viewing, displaying,  performing, copying or distributing any Project Gutenberg™ works  unless you comply with paragraph 1.E.8 or 1.E.9.    1.E.8. You may charge a reasonable fee for copies of or providing  access to or distributing Project Gutenberg™ electronic works  provided that:        • You pay a royalty fee of 20% of the gross profits you derive from          the use of Project Gutenberg™ works calculated using the method          you already use to calculate your applicable taxes. The fee is owed          to the owner of the Project Gutenberg™ trademark, but he has          agreed to donate royalties under this paragraph to the Project          Gutenberg Literary Archive Foundation. Royalty payments must be paid          within 60 days following each date on which you prepare (or are          legally required to prepare) your periodic tax returns. Royalty          payments should be clearly marked as such and sent to the Project          Gutenberg Literary Archive Foundation at the address specified in          Section 4, “Information about donations to the Project Gutenberg          Literary Archive Foundation.”            • You provide a full refund of any money paid by a user who notifies          you in writing (or by e-mail) within 30 days of receipt that s/he          does not agree to the terms of the full Project Gutenberg™          License. You must require such a user to return or destroy all          copies of the works possessed in a physical medium and discontinue          all use of and all access to other copies of Project Gutenberg™          works.            • You provide, in accordance with paragraph 1.F.3, a full refund of          any money paid for a work or a replacement copy, if a defect in the          electronic work is discovered and reported to you within 90 days of          receipt of the work.            • You comply with all other terms of this agreement for free          distribution of Project Gutenberg™ works.          1.E.9. If you wish to charge a fee or distribute a Project  Gutenberg™ electronic work or group of works on different terms than  are set forth in this agreement, you must obtain permission in writing  from the Project Gutenberg Literary Archive Foundation, the manager of  the Project Gutenberg™ trademark. Contact the Foundation as set  forth in Section 3 below.    1.F.    1.F.1. Project Gutenberg volunteers and employees expend considerable  effort to identify, do copyright research on, transcribe and proofread  works not protected by U.S. copyright law in creating the Project  Gutenberg™ collection. Despite these efforts, Project Gutenberg™  electronic works, and the medium on which they may be stored, may  contain “Defects,” such as, but not limited to, incomplete, inaccurate  or corrupt data, transcription errors, a copyright or other  intellectual property infringement, a defective or damaged disk or  other medium, a computer virus, or computer codes that damage or  cannot be read by your equipment.    1.F.2. LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the “Right  of Replacement or Refund” described in paragraph 1.F.3, the Project  Gutenberg Literary Archive Foundation, the owner of the Project  Gutenberg™ trademark, and any other party distributing a Project  Gutenberg™ electronic work under this agreement, disclaim all  liability to you for damages, costs and expenses, including legal  fees. YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT  LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE  PROVIDED IN PARAGRAPH 1.F.3. YOU AGREE THAT THE FOUNDATION, THE  TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE  LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR  INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH  DAMAGE.    1.F.3. LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a  defect in this electronic work within 90 days of receiving it, you can  receive a refund of the money (if any) you paid for it by sending a  written explanation to the person you received the work from. If you  received the work on a physical medium, you must return the medium  with your written explanation. The person or entity that provided you  with the defective work may elect to provide a replacement copy in  lieu of a refund. If you received the work electronically, the person  or entity providing it to you may choose to give you a second  opportunity to receive the work electronically in lieu of a refund. If  the second copy is also defective, you may demand a refund in writing  without further opportunities to fix the problem.    1.F.4. Except for the limited right of replacement or refund set forth  in paragraph 1.F.3, this work is provided to you ‘AS-IS’, WITH NO  OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT  LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.    1.F.5. Some states do not allow disclaimers of certain implied  warranties or the exclusion or limitation of certain types of  damages. If any disclaimer or limitation set forth in this agreement  violates the law of the state applicable to this agreement, the  agreement shall be interpreted to make the maximum disclaimer or  limitation permitted by the applicable state law. The invalidity or  unenforceability of any provision of this agreement shall not void the  remaining provisions.    1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the  trademark owner, any agent or employee of the Foundation, anyone  providing copies of Project Gutenberg™ electronic works in  accordance with this agreement, and any volunteers associated with the  production, promotion and distribution of Project Gutenberg™  electronic works, harmless from all liability, costs and expenses,  including legal fees, that arise directly or indirectly from any of  the following which you do or cause to occur: (a) distribution of this  or any Project Gutenberg™ work, (b) alteration, modification, or  additions or deletions to any Project Gutenberg™ work, and (c) any  Defect you cause.    Section 2. Information about the Mission of Project Gutenberg™    Project Gutenberg™ is synonymous with the free distribution of  electronic works in formats readable by the widest variety of  computers including obsolete, old, middle-aged and new computers. It  exists because of the efforts of hundreds of volunteers and donations  from people in all walks of life.    Volunteers and financial support to provide volunteers with the  assistance they need are critical to reaching Project Gutenberg™’s  goals and ensuring that the Project Gutenberg™ collection will  remain freely available for generations to come. In 2001, the Project  Gutenberg Literary Archive Foundation was created to provide a secure  and permanent future for Project Gutenberg™ and future  generations. To learn more about the Project Gutenberg Literary  Archive Foundation and how your efforts and donations can help, see  Sections 3 and 4 and the Foundation information page at www.gutenberg.org.    Section 3. Information about the Project Gutenberg Literary Archive Foundation    The Project Gutenberg Literary Archive Foundation is a non-profit  501(c)(3) educational corporation organized under the laws of the  state of Mississippi and granted tax exempt status by the Internal  Revenue Service. The Foundation’s EIN or federal tax identification  number is 64-6221541. Contributions to the Project Gutenberg Literary  Archive Foundation are tax deductible to the full extent permitted by  U.S. federal laws and your state’s laws.    The Foundation’s business office is located at 809 North 1500 West,  Salt Lake City, UT 84116, (801) 596-1887. Email contact links and up  to date contact information can be found at the Foundation’s website  and official page at www.gutenberg.org/contact    Section 4. Information about Donations to the Project Gutenberg  Literary Archive Foundation    Project Gutenberg™ depends upon and cannot survive without widespread  public support and donations to carry out its mission of  increasing the number of public domain and licensed works that can be  freely distributed in machine-readable form accessible by the widest  array of equipment including outdated equipment. Many small donations  ($1 to $5,000) are particularly important to maintaining tax exempt  status with the IRS.    The Foundation is committed to complying with the laws regulating  charities and charitable donations in all 50 states of the United  States. Compliance requirements are not uniform and it takes a  considerable effort, much paperwork and many fees to meet and keep up  with these requirements. We do not solicit donations in locations  where we have not received written confirmation of compliance. To SEND  DONATIONS or determine the status of compliance for any particular state  visit www.gutenberg.org/donate.    While we cannot and do not solicit contributions from states where we  have not met the solicitation requirements, we know of no prohibition  against accepting unsolicited donations from donors in such states who  approach us with offers to donate.    International donations are gratefully accepted, but we cannot make  any statements concerning tax treatment of donations received from  outside the United States. U.S. laws alone swamp our small staff.    Please check the Project Gutenberg web pages for current donation  methods and addresses. Donations are accepted in a number of other  ways including checks, online payments and credit card donations. To  donate, please visit: www.gutenberg.org/donate.    Section 5. General Information About Project Gutenberg™ electronic works    Professor Michael S. Hart was the originator of the Project  Gutenberg™ concept of a library of electronic works that could be  freely shared with anyone. For forty years, he produced and  distributed Project Gutenberg™ eBooks with only a loose network of  volunteer support.    Project Gutenberg™ eBooks are often created from several printed  editions, all of which are confirmed as not protected by copyright in  the U.S. unless a copyright notice is included. Thus, we do not  necessarily keep eBooks in compliance with any particular paper  edition.    Most people start at our website which has the main PG search  facility: www.gutenberg.org.    This website includes information about Project Gutenberg™,  including how to make donations to the Project Gutenberg Literary  Archive Foundation, how to help produce our new eBooks, and how to  subscribe to our email newsletter to hear about new eBooks.      \n"
     ]
    }
   ],
   "source": [
    "# also need to remove the legalese from the end of the book\n",
    "\n",
    "print(war_ot_worlds[342639:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1c1d1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "war_ot_worlds = war_ot_worlds[:342639]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "4fc4d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nted me, among the dead.\n"
     ]
    }
   ],
   "source": [
    "print(war_ot_worlds[342615:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad39a39e",
   "metadata": {},
   "source": [
    "#### Txt locally\n",
    "If you'd rather use a file on your computer, here's the code -- you just need to save the text file in your local directory, and change the variables throughout. \n",
    "\n",
    "The example is a report from the [Congressional Research Service](https://www.everycrsreport.com/files/2020-11-10_R45178_62d6238caecf6c02ddf495be33b3439f09eed744.pdf) on AI and National Security."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bfe44ab",
   "metadata": {},
   "source": [
    "# read a file you have stored locally\n",
    "f = open(\"2020-11-10_CRS_ArtificialIntelligenceNationalSecurity.txt\", 'r', encoding=\"utf8\").read() # need UTF8 encoding to read file\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    f = f.replace(char, \" \")\n",
    "\n",
    "# check\n",
    "print(f[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "8c4c9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'one', 'the', 'coming', 'of', 'the', 'martians', 'i', 'the', 'eve', 'of', 'the', 'war', 'no', 'one', 'would', 'have', 'believed', 'in', 'the', 'last', 'years', 'of', 'the', 'nineteenth', 'century', 'that', 'this', 'world', 'was', 'being', 'watched', 'keenly', 'and', 'closely', 'by', 'intelligences', 'greater', 'than', 'mans', 'and', 'yet', 'as', 'mortal', 'as', 'his', 'own', 'that', 'as', 'men']\n"
     ]
    }
   ],
   "source": [
    "# this is simplified for demonstration\n",
    "def sample_clean_text(text: str):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation from text\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # return your tokens\n",
    "    return tokens\n",
    "\n",
    "# call the function\n",
    "sample_tokens = sample_clean_text(text = war_ot_worlds)\n",
    "\n",
    "# check\n",
    "print(sample_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "94d828dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book', 'one'),\n",
       " ('one', 'the'),\n",
       " ('the', 'coming'),\n",
       " ('coming', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'martians'),\n",
       " ('martians', 'i'),\n",
       " ('i', 'the'),\n",
       " ('the', 'eve'),\n",
       " ('eve', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'war'),\n",
       " ('war', 'no'),\n",
       " ('no', 'one'),\n",
       " ('one', 'would')]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bigrams from the sample tokens\n",
    "my_bigrams = bigrams(sample_tokens)\n",
    "\n",
    "# check\n",
    "list(my_bigrams)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239deb54",
   "metadata": {},
   "source": [
    "# Part 2 - creating an ngram model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "9aba6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 is for bigrams\n",
    "n = 2\n",
    "#specify the text you want to use\n",
    "text = war_ot_worlds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be61c83",
   "metadata": {},
   "source": [
    "Now we are going to use an NLTK shortcut for preprocessing. This will:\n",
    "* pad all of the sentences with `<s>` and `</s>` to train on sentence boundaries, too.\n",
    "* create both unigrams and bigrams\n",
    "* create a training set and a full vocab to train on\n",
    "\n",
    "We need to give it a pre-tokenized text (we'll use nltk's tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6276da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['book', 'one', 'the', 'coming', 'of', 'the', 'martians', 'i', '.'], ['the', 'eve', 'of', 'the', 'war', '.'], ['no', 'one', 'would', 'have', 'believed', 'in', 'the', 'last', 'years', 'of', 'the', 'nineteenth', 'century', 'that', 'this', 'world', 'was', 'being', 'watched', 'keenly', 'and', 'closely', 'by', 'intelligences', 'greater', 'than', 'man', '’', 's', 'and', 'yet', 'as', 'mortal', 'as', 'his', 'own', ';', 'that', 'as', 'men', 'busied', 'themselves', 'about', 'their', 'various', 'concerns', 'they', 'were', 'scrutinised', 'and', 'studied', ',', 'perhaps', 'almost', 'as', 'narrowly', 'as', 'a', 'man', 'with', 'a', 'microscope', 'might', 'scrutinise', 'the', 'transient', 'creatures', 'that', 'swarm', 'and', 'multiply', 'in', 'a', 'drop', 'of', 'water', '.'], ['with', 'infinite', 'complacency', 'men', 'went', 'to', 'and', 'fro', 'over', 'this', 'globe', 'about', 'their', 'little', 'affairs', ',', 'serene', 'in', 'their', 'assurance', 'of', 'their', 'empire', 'over', 'matter', '.']]\n"
     ]
    }
   ],
   "source": [
    "# step 1: tokenize the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# step 2: tokenize each sentence into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# step 3: convert each word to lowercase\n",
    "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
    "\n",
    "#notice the sentence breaks and what the first 10 items of the tokenized text\n",
    "print(tokenized_text[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1253ba97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'one', 'would', 'have', 'believed', 'in', 'the', 'last', 'years', 'of', 'the', 'nineteenth', 'century', 'that', 'this', 'world', 'was', 'being', 'watched', 'keenly', 'and', 'closely', 'by', 'intelligences', 'greater', 'than', 'man', '’', 's', 'and', 'yet', 'as', 'mortal', 'as', 'his', 'own', ';', 'that', 'as', 'men', 'busied', 'themselves', 'about', 'their', 'various', 'concerns', 'they', 'were', 'scrutinised', 'and', 'studied', ',', 'perhaps', 'almost', 'as', 'narrowly', 'as', 'a', 'man', 'with', 'a', 'microscope', 'might', 'scrutinise', 'the', 'transient', 'creatures', 'that', 'swarm', 'and', 'multiply', 'in', 'a', 'drop', 'of', 'water', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7a3de",
   "metadata": {},
   "source": [
    "Why tokenize sentences and words?\n",
    "\n",
    "We want to be able to retain sentence boundaries to encode that, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9fbc5554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'one', 'the', 'coming', 'of', 'the', 'martians', 'i', '.']\n"
     ]
    }
   ],
   "source": [
    "# notice what the first 10 items of the vocabulary are:\n",
    "#print(text[:10])\n",
    "print(tokenized_text[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c306af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imported this function from nltk\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "ca61c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "# we imported this function from nltk linear models (lm) \n",
    "# it is for Maximum Likelihood Estimation\n",
    "\n",
    "# MLE is the model we will use\n",
    "lm = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "c3ecfc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currently the vocab length is 0: it has no prior knowledge\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "141795d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7203"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "# training data is the bigrams and unigrams \n",
    "# the vocab is all the sentence tokens in the corpus \n",
    "\n",
    "lm.fit(train_data, padded_sents)\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4455cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module nltk.lm.api:\n",
      "\n",
      "fit(self, text, vocabulary_text=None)\n",
      "    Trains the model on a text.\n",
      "    \n",
      "    :param text: Training text as a sequence of sentences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MLE.fit) # this breaks the following code!  Not sure why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c7470ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_text[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "941458b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('with', 'infinite', 'complacency', 'men', 'went', 'to', 'and', 'fro', 'over', 'this', 'globe', 'about', 'their', 'little', 'affairs', ',', 'serene', 'in', 'their', 'assurance', 'of', 'their', 'empire', 'over', 'matter', '.')\n"
     ]
    }
   ],
   "source": [
    "# inspect the model's vocabulary. \n",
    "# be sure that a sentence you know exists (from tokenized_text) is in the \n",
    "print(lm.vocab.lookup(tokenized_text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "8e06f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<UNK>', 'is', 'no', 'spoon', '.')\n"
     ]
    }
   ],
   "source": [
    "print(lm.vocab.lookup([\"There\", \"is\", \"no\", \"spoon\", \".\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "1d09baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'is', 'no', 'spoon', '.']\n"
     ]
    }
   ],
   "source": [
    "my_list = [\"There\", \"is\", \"no\", \"spoon\", \".\"]\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "67a85cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<UNK>', 'is', 'no', 'spoon', '.')\n"
     ]
    }
   ],
   "source": [
    "print(lm.vocab.lookup(my_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4af78e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book\n"
     ]
    }
   ],
   "source": [
    "print(lm.vocab.lookup(tokenized_text[0][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d820f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('then', 'wear', 'the', 'gold', 'hat', '<UNK>', '.')\n"
     ]
    }
   ],
   "source": [
    "# see what happens when we include a word that is not in the vocab. \n",
    "print(lm.vocab.lookup('then wear the gold hat iphone .'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0207d680",
   "metadata": {},
   "source": [
    "What did the model replace 'iphone' with? \n",
    "\n",
    "Given that it didn't just return an \"out of vocab\" error, what does that mean about our model? \n",
    "\n",
    "Our model added '<UNK>' to our vocabulary so that when we train it on new data it will not crash when it encounters wordls that are not in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "da9cf2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3259961546111516e-05"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times does alien appear in the model?\n",
    "print(lm.counts['alien'])\n",
    "\n",
    "# what is the probability of alien appearing? \n",
    "# this is technically the relative frequency of alien appearing \n",
    "lm.score('alien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "266346a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0003182390771066764"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times does world appear in the model?\n",
    "print(lm.counts['world'])\n",
    "\n",
    "# what is the probability of world appearing? \n",
    "# this is technically the relative frequency of world appearing \n",
    "lm.score('world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f9369bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how often does (world, and) occur and what is the relative frequency?\n",
    "print(lm.counts[['world']]['war'])\n",
    "lm.score('war', 'world'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a82045b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0021481137704700655"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times does martians appear in the model?\n",
    "print(lm.counts['martians'])\n",
    "\n",
    "# what is the probability of martians appearing? \n",
    "# this is technically the relative frequency of martians appearing \n",
    "lm.score('martians')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "ab8c7d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09876543209876543"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how often does (martians, were) occur and what is the relative frequency?\n",
    "print(lm.counts[['martians']]['were'])\n",
    "lm.score('were', 'martians'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "83ca4cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09876543209876543"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NLTK Documentation:\n",
    "# Here’s how you get the score for a word given some preceding context. \n",
    "\n",
    "# For example we want to know what is the chance that “were” is preceded by “martians”.\n",
    "\n",
    "lm.score(\"were\", [\"martians\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "174f226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the score of 'UNK'? \n",
    "\n",
    "lm.score(\"<UNK>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c0444",
   "metadata": {},
   "source": [
    "Does the relative frequency of 'UNK' change your assumption about how the model behaves? \n",
    "\n",
    "How should we change our model to account for the fact the `<UNK>` words are not accounted for by the model? \n",
    "\n",
    "(We would want to implement Laplace smoothing or something similar to account for the unknown words per [NATURAL LANGUAGE PROCESSING N-gram language models: Part 1: Unigram model by Khanh Nguyen](https://medium.com/mti-technology/n-gram-language-model-b7c2fc322799)\n",
    "\n",
    "Note: *Programmatically implementing this solution is beyond the scope of this course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d621b05",
   "metadata": {},
   "source": [
    "## Generate text\n",
    "We want to start our sentence with a word, and use that to predict all the words that come after that. We'll specify how long it should be. \n",
    "\n",
    "There is a certain amount of randomness encoded into n-gram models. This prevents a model from becoming entirely deterministic. Maximum Likelihood Estimation without some degree of randomness will only produce the most likely result every time. Setting Random Seed means we will get the same result every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6e217db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['park', ',', 'and', 'drawn', 'closely', 'to', 'the', 'captain', 'lay', '.', '</s>', 'in', 'a', 'ditch', 'for', 'my', 'brother', 'saw', 'the', 'advance']\n"
     ]
    }
   ],
   "source": [
    "# generate a 20 word sentence starting with the word, 'martians'\n",
    "\n",
    "print(lm.generate(20, text_seed= 'martians', random_seed=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91b7a6",
   "metadata": {},
   "source": [
    "This next code block is just to clean up the tokenized words and make them easier on human eyes. It is literally a detokenizer, which removes some extraneous text markup and reconciles some words back together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5113674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2846e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'park, and drawn closely to the captain lay.'"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now generate sentences that look much nicer. \n",
    "generate_sent(lm, 40, text_seed='martians', random_seed = 42)\n",
    "# Stops after exactly one sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ad126",
   "metadata": {},
   "source": [
    "Try a few more sentences, and try out another text. Once you are satisfied with what ngrams can (and cannot) do - post your code to your Github or another site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "347d4032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what these strange tidings, one thinks of the cylinders have you are driving us and disease and turned back and silent mass of baker street—portman square, and striding by the cylinder, according to the dull radiation arrested'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now generate sentences that look much nicer. \n",
    "generate_sent(lm, 40, text_seed='martians', random_seed = 20)\n",
    "# Stops after exactly one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "86431796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'account for the crest of his against the cylinder, and made a tall against the handling-machine, felled and myself now?'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='martians', random_seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "4627b44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'account of its length might have filled my terror not see the sight of a multitude that the silence, astonished, with three or awake and dispersed by a puff of the last time, skirting the road and'"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='martians', random_seed = 547)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac55bd1",
   "metadata": {},
   "source": [
    "# Alice in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "1e45e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of Alice's Adventures in Wonderland        This ebook is for the use of\n"
     ]
    }
   ],
   "source": [
    "# you will need to leverage the requests package\n",
    "r = requests.get(r'https://www.gutenberg.org/cache/epub/28885/pg28885.txt')\n",
    "alice = r.text\n",
    "\n",
    "# first, remove unwanted new line and tab characters from the text\n",
    "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
    "    alice = alice.replace(char, \" \")\n",
    "\n",
    "# check\n",
    "print(alice[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "2bd99a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALICE was beginning to get very tired\n"
     ]
    }
   ],
   "source": [
    "print(alice[6363:6400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "6e3a0970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALICE was beginning to get very tired of sitting by her  sister on the bank, and of having nothing to do: once or twice she had  peeped into the book \n"
     ]
    }
   ],
   "source": [
    "# remove the metadata at the beginning - this is slightly different for each book\n",
    "alice = alice[6363:]\n",
    "print(alice[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "91f0c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170878\n"
     ]
    }
   ],
   "source": [
    "print(len(alice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "c07e517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18881"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "361520 - 342639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d54cb203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151997"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "170878 - 18881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "4bcf5f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       *** END OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***                      Updated editions will replace the previous one—the old editions will  be renamed.    Creating the works from print editions not protected by U.S. copyright  law means that no one owns a United States copyright in these works,  so the Foundation (and you!) can copy and distribute it in the United  States without permission and without paying copyright  royalties. Special rules, set forth in the General Terms of Use part  of this license, apply to copying and distributing Project  Gutenberg™ electronic works to protect the PROJECT GUTENBERG™  concept and trademark. Project Gutenberg is a registered trademark,  and may not be used if you charge for an eBook, except by following  the terms of the trademark license, including paying royalties for use  of the Project Gutenberg trademark. If you do not charge anything for  copies of this eBook, complying with the trademark license is very  easy. You may use this eBook for nearly any purpose such as creation  of derivative works, reports, performances and research. Project  Gutenberg eBooks may be modified and printed and given away—you may  do practically ANYTHING in the United States with eBooks not protected  by U.S. copyright law. Redistribution is subject to the trademark  license, especially commercial redistribution.      START: FULL LICENSE    THE FULL PROJECT GUTENBERG LICENSE    PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK    To protect the Project Gutenberg™ mission of promoting the free  distribution of electronic works, by using or distributing this work  (or any other work associated in any way with the phrase “Project  Gutenberg”), you agree to comply with all the terms of the Full  Project Gutenberg™ License available with this file or online at  www.gutenberg.org/license.    Section 1. General Terms of Use and Redistributing Project Gutenberg™  electronic works    1.A. By reading or using any part of this Project Gutenberg™  electronic work, you indicate that you have read, understand, agree to  and accept all the terms of this license and intellectual property  (trademark/copyright) agreement. If you do not agree to abide by all  the terms of this agreement, you must cease using and return or  destroy all copies of Project Gutenberg™ electronic works in your  possession. If you paid a fee for obtaining a copy of or access to a  Project Gutenberg™ electronic work and you do not agree to be bound  by the terms of this agreement, you may obtain a refund from the person  or entity to whom you paid the fee as set forth in paragraph 1.E.8.    1.B. “Project Gutenberg” is a registered trademark. It may only be  used on or associated in any way with an electronic work by people who  agree to be bound by the terms of this agreement. There are a few  things that you can do with most Project Gutenberg™ electronic works  even without complying with the full terms of this agreement. See  paragraph 1.C below. There are a lot of things you can do with Project  Gutenberg™ electronic works if you follow the terms of this  agreement and help preserve free future access to Project Gutenberg™  electronic works. See paragraph 1.E below.    1.C. The Project Gutenberg Literary Archive Foundation (“the  Foundation” or PGLAF), owns a compilation copyright in the collection  of Project Gutenberg™ electronic works. Nearly all the individual  works in the collection are in the public domain in the United  States. If an individual work is unprotected by copyright law in the  United States and you are located in the United States, we do not  claim a right to prevent you from copying, distributing, performing,  displaying or creating derivative works based on the work as long as  all references to Project Gutenberg are removed. Of course, we hope  that you will support the Project Gutenberg™ mission of promoting  free access to electronic works by freely sharing Project Gutenberg™  works in compliance with the terms of this agreement for keeping the  Project Gutenberg™ name associated with the work. You can easily  comply with the terms of this agreement by keeping this work in the  same format with its attached full Project Gutenberg™ License when  you share it without charge with others.    1.D. The copyright laws of the place where you are located also govern  what you can do with this work. Copyright laws in most countries are  in a constant state of change. If you are outside the United States,  check the laws of your country in addition to the terms of this  agreement before downloading, copying, displaying, performing,  distributing or creating derivative works based on this work or any  other Project Gutenberg™ work. The Foundation makes no  representations concerning the copyright status of any work in any  country other than the United States.    1.E. Unless you have removed all references to Project Gutenberg:    1.E.1. The following sentence, with active links to, or other  immediate access to, the full Project Gutenberg™ License must appear  prominently whenever any copy of a Project Gutenberg™ work (any work  on which the phrase “Project Gutenberg” appears, or with which the  phrase “Project Gutenberg” is associated) is accessed, displayed,  performed, viewed, copied or distributed:        This eBook is for the use of anyone anywhere in the United States and most      other parts of the world at no cost and with almost no restrictions      whatsoever. You may copy it, give it away or re-use it under the terms      of the Project Gutenberg License included with this eBook or online      at www.gutenberg.org. If you      are not located in the United States, you will have to check the laws      of the country where you are located before using this eBook.      1.E.2. If an individual Project Gutenberg™ electronic work is  derived from texts not protected by U.S. copyright law (does not  contain a notice indicating that it is posted with permission of the  copyright holder), the work can be copied and distributed to anyone in  the United States without paying any fees or charges. If you are  redistributing or providing access to a work with the phrase “Project  Gutenberg” associated with or appearing on the work, you must comply  either with the requirements of paragraphs 1.E.1 through 1.E.7 or  obtain permission for the use of the work and the Project Gutenberg™  trademark as set forth in paragraphs 1.E.8 or 1.E.9.    1.E.3. If an individual Project Gutenberg™ electronic work is posted  with the permission of the copyright holder, your use and distribution  must comply with both paragraphs 1.E.1 through 1.E.7 and any  additional terms imposed by the copyright holder. Additional terms  will be linked to the Project Gutenberg™ License for all works  posted with the permission of the copyright holder found at the  beginning of this work.    1.E.4. Do not unlink or detach or remove the full Project Gutenberg™  License terms from this work, or any files containing a part of this  work or any other work associated with Project Gutenberg™.    1.E.5. Do not copy, display, perform, distribute or redistribute this  electronic work, or any part of this electronic work, without  prominently displaying the sentence set forth in paragraph 1.E.1 with  active links or immediate access to the full terms of the Project  Gutenberg™ License.    1.E.6. You may convert to and distribute this work in any binary,  compressed, marked up, nonproprietary or proprietary form, including  any word processing or hypertext form. However, if you provide access  to or distribute copies of a Project Gutenberg™ work in a format  other than “Plain Vanilla ASCII” or other format used in the official  version posted on the official Project Gutenberg™ website  (www.gutenberg.org), you must, at no additional cost, fee or expense  to the user, provide a copy, a means of exporting a copy, or a means  of obtaining a copy upon request, of the work in its original “Plain  Vanilla ASCII” or other form. Any alternate format must include the  full Project Gutenberg™ License as specified in paragraph 1.E.1.    1.E.7. Do not charge a fee for access to, viewing, displaying,  performing, copying or distributing any Project Gutenberg™ works  unless you comply with paragraph 1.E.8 or 1.E.9.    1.E.8. You may charge a reasonable fee for copies of or providing  access to or distributing Project Gutenberg™ electronic works  provided that:        • You pay a royalty fee of 20% of the gross profits you derive from          the use of Project Gutenberg™ works calculated using the method          you already use to calculate your applicable taxes. The fee is owed          to the owner of the Project Gutenberg™ trademark, but he has          agreed to donate royalties under this paragraph to the Project          Gutenberg Literary Archive Foundation. Royalty payments must be paid          within 60 days following each date on which you prepare (or are          legally required to prepare) your periodic tax returns. Royalty          payments should be clearly marked as such and sent to the Project          Gutenberg Literary Archive Foundation at the address specified in          Section 4, “Information about donations to the Project Gutenberg          Literary Archive Foundation.”            • You provide a full refund of any money paid by a user who notifies          you in writing (or by e-mail) within 30 days of receipt that s/he          does not agree to the terms of the full Project Gutenberg™          License. You must require such a user to return or destroy all          copies of the works possessed in a physical medium and discontinue          all use of and all access to other copies of Project Gutenberg™          works.            • You provide, in accordance with paragraph 1.F.3, a full refund of          any money paid for a work or a replacement copy, if a defect in the          electronic work is discovered and reported to you within 90 days of          receipt of the work.            • You comply with all other terms of this agreement for free          distribution of Project Gutenberg™ works.          1.E.9. If you wish to charge a fee or distribute a Project  Gutenberg™ electronic work or group of works on different terms than  are set forth in this agreement, you must obtain permission in writing  from the Project Gutenberg Literary Archive Foundation, the manager of  the Project Gutenberg™ trademark. Contact the Foundation as set  forth in Section 3 below.    1.F.    1.F.1. Project Gutenberg volunteers and employees expend considerable  effort to identify, do copyright research on, transcribe and proofread  works not protected by U.S. copyright law in creating the Project  Gutenberg™ collection. Despite these efforts, Project Gutenberg™  electronic works, and the medium on which they may be stored, may  contain “Defects,” such as, but not limited to, incomplete, inaccurate  or corrupt data, transcription errors, a copyright or other  intellectual property infringement, a defective or damaged disk or  other medium, a computer virus, or computer codes that damage or  cannot be read by your equipment.    1.F.2. LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the “Right  of Replacement or Refund” described in paragraph 1.F.3, the Project  Gutenberg Literary Archive Foundation, the owner of the Project  Gutenberg™ trademark, and any other party distributing a Project  Gutenberg™ electronic work under this agreement, disclaim all  liability to you for damages, costs and expenses, including legal  fees. YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT  LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE  PROVIDED IN PARAGRAPH 1.F.3. YOU AGREE THAT THE FOUNDATION, THE  TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE  LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR  INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH  DAMAGE.    1.F.3. LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a  defect in this electronic work within 90 days of receiving it, you can  receive a refund of the money (if any) you paid for it by sending a  written explanation to the person you received the work from. If you  received the work on a physical medium, you must return the medium  with your written explanation. The person or entity that provided you  with the defective work may elect to provide a replacement copy in  lieu of a refund. If you received the work electronically, the person  or entity providing it to you may choose to give you a second  opportunity to receive the work electronically in lieu of a refund. If  the second copy is also defective, you may demand a refund in writing  without further opportunities to fix the problem.    1.F.4. Except for the limited right of replacement or refund set forth  in paragraph 1.F.3, this work is provided to you ‘AS-IS’, WITH NO  OTHER WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT  LIMITED TO WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY PURPOSE.    1.F.5. Some states do not allow disclaimers of certain implied  warranties or the exclusion or limitation of certain types of  damages. If any disclaimer or limitation set forth in this agreement  violates the law of the state applicable to this agreement, the  agreement shall be interpreted to make the maximum disclaimer or  limitation permitted by the applicable state law. The invalidity or  unenforceability of any provision of this agreement shall not void the  remaining provisions.    1.F.6. INDEMNITY - You agree to indemnify and hold the Foundation, the  trademark owner, any agent or employee of the Foundation, anyone  providing copies of Project Gutenberg™ electronic works in  accordance with this agreement, and any volunteers associated with the  production, promotion and distribution of Project Gutenberg™  electronic works, harmless from all liability, costs and expenses,  including legal fees, that arise directly or indirectly from any of  the following which you do or cause to occur: (a) distribution of this  or any Project Gutenberg™ work, (b) alteration, modification, or  additions or deletions to any Project Gutenberg™ work, and (c) any  Defect you cause.    Section 2. Information about the Mission of Project Gutenberg™    Project Gutenberg™ is synonymous with the free distribution of  electronic works in formats readable by the widest variety of  computers including obsolete, old, middle-aged and new computers. It  exists because of the efforts of hundreds of volunteers and donations  from people in all walks of life.    Volunteers and financial support to provide volunteers with the  assistance they need are critical to reaching Project Gutenberg™’s  goals and ensuring that the Project Gutenberg™ collection will  remain freely available for generations to come. In 2001, the Project  Gutenberg Literary Archive Foundation was created to provide a secure  and permanent future for Project Gutenberg™ and future  generations. To learn more about the Project Gutenberg Literary  Archive Foundation and how your efforts and donations can help, see  Sections 3 and 4 and the Foundation information page at www.gutenberg.org.    Section 3. Information about the Project Gutenberg Literary Archive Foundation    The Project Gutenberg Literary Archive Foundation is a non-profit  501(c)(3) educational corporation organized under the laws of the  state of Mississippi and granted tax exempt status by the Internal  Revenue Service. The Foundation’s EIN or federal tax identification  number is 64-6221541. Contributions to the Project Gutenberg Literary  Archive Foundation are tax deductible to the full extent permitted by  U.S. federal laws and your state’s laws.    The Foundation’s business office is located at 809 North 1500 West,  Salt Lake City, UT 84116, (801) 596-1887. Email contact links and up  to date contact information can be found at the Foundation’s website  and official page at www.gutenberg.org/contact    Section 4. Information about Donations to the Project Gutenberg  Literary Archive Foundation    Project Gutenberg™ depends upon and cannot survive without widespread  public support and donations to carry out its mission of  increasing the number of public domain and licensed works that can be  freely distributed in machine-readable form accessible by the widest  array of equipment including outdated equipment. Many small donations  ($1 to $5,000) are particularly important to maintaining tax exempt  status with the IRS.    The Foundation is committed to complying with the laws regulating  charities and charitable donations in all 50 states of the United  States. Compliance requirements are not uniform and it takes a  considerable effort, much paperwork and many fees to meet and keep up  with these requirements. We do not solicit donations in locations  where we have not received written confirmation of compliance. To SEND  DONATIONS or determine the status of compliance for any particular state  visit www.gutenberg.org/donate.    While we cannot and do not solicit contributions from states where we  have not met the solicitation requirements, we know of no prohibition  against accepting unsolicited donations from donors in such states who  approach us with offers to donate.    International donations are gratefully accepted, but we cannot make  any statements concerning tax treatment of donations received from  outside the United States. U.S. laws alone swamp our small staff.    Please check the Project Gutenberg web pages for current donation  methods and addresses. Donations are accepted in a number of other  ways including checks, online payments and credit card donations. To  donate, please visit: www.gutenberg.org/donate.    Section 5. General Information About Project Gutenberg™ electronic works    Professor Michael S. Hart was the originator of the Project  Gutenberg™ concept of a library of electronic works that could be  freely shared with anyone. For forty years, he produced and  distributed Project Gutenberg™ eBooks with only a loose network of  volunteer support.    Project Gutenberg™ eBooks are often created from several printed  editions, all of which are confirmed as not protected by copyright in  the U.S. unless a copyright notice is included. Thus, we do not  necessarily keep eBooks in compliance with any particular paper  edition.    Most people start at our website which has the main PG search  facility: www.gutenberg.org.    This website includes information about Project Gutenberg™,  including how to make donations to the Project Gutenberg Literary  Archive Foundation, how to help produce our new eBooks, and how to  subscribe to our email newsletter to hear about new eBooks.      \n"
     ]
    }
   ],
   "source": [
    "# also need to remove the legalese from the end of the book\n",
    "print(alice[151997:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "00baf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = alice[:151997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f0fca4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s, remembering her own child-life, and the happy summer days.      THE END\n"
     ]
    }
   ],
   "source": [
    "print(alice[150797:150871])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "5369a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = alice[:150871]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "873ef00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "their simple  joys, remembering her own child-life, and the happy summer days.      THE END\n"
     ]
    }
   ],
   "source": [
    "print(alice[150780:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e562b7",
   "metadata": {},
   "source": [
    "# Part 2 - creating an ngram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "a1067ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 is for bigrams\n",
    "n = 2\n",
    "#specify the text you want to use\n",
    "text = alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9908e7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', '``', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"''\", 'thought', 'alice', ',', '``', 'without', 'pictures', 'or', 'conversations', '?', \"''\"], ['so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', ')', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy-chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', ',', 'when', 'suddenly', 'a', 'white', 'rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her', '.'], ['there', 'was', 'nothing', 'so', '_very_', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'alice', 'think', 'it', 'so', '_very_', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'rabbit', 'say', 'to', 'itself', ',', '``', 'oh', 'dear', '!'], ['oh', 'dear', '!']]\n"
     ]
    }
   ],
   "source": [
    "# step 1: tokenize the text into sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# step 2: tokenize each sentence into words\n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# step 3: convert each word to lowercase\n",
    "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
    "\n",
    "#notice the sentence breaks and what the first 10 items of the tokenized text\n",
    "print(tokenized_text[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "56c9daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'was', 'nothing', 'so', '_very_', 'remarkable', 'in', 'that', ';', 'nor', 'did', 'alice', 'think', 'it', 'so', '_very_', 'much', 'out', 'of', 'the', 'way', 'to', 'hear', 'the', 'rabbit', 'say', 'to', 'itself', ',', '``', 'oh', 'dear', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3ea4337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by']\n"
     ]
    }
   ],
   "source": [
    "# notice what the first 10 items of the vocabulary are:\n",
    "#print(text[:10])\n",
    "print(tokenized_text[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "196d3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imported this function from nltk\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "8fca2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "# we imported this function from nltk linear models (lm) \n",
    "# it is for Maximum Likelihood Estimation\n",
    "\n",
    "# MLE is the model we will use\n",
    "lm = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e1261a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2778"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "# training data is the bigrams and unigrams \n",
    "# the vocab is all the sentence tokens in the corpus \n",
    "\n",
    "lm.fit(train_data, padded_sents)\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5410b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('oh', 'dear', '!')\n"
     ]
    }
   ],
   "source": [
    "# inspect the model's vocabulary. \n",
    "# be sure that a sentence you know exists (from tokenized_text) is in the \n",
    "print(lm.vocab.lookup(tokenized_text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "ec17406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<UNK>', 'is', 'no', 'spoon', '.')\n"
     ]
    }
   ],
   "source": [
    "print(lm.vocab.lookup([\"There\", \"is\", \"no\", \"spoon\", \".\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "0c199b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice\n"
     ]
    }
   ],
   "source": [
    "print(lm.vocab.lookup(tokenized_text[0][0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "a68cd9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('then', '<UNK>', 'the', '<UNK>', 'hat', '<UNK>', '.')\n"
     ]
    }
   ],
   "source": [
    "# see what happens when we include a word that is not in the vocab. \n",
    "print(lm.vocab.lookup('then wear the gold hat iphone .'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a421d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010450754776733875"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times does alice appear in the model?\n",
    "print(lm.counts['alice'])\n",
    "\n",
    "# what is the probability of alice appearing? \n",
    "# this is technically the relative frequency of alice appearing \n",
    "lm.score('alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "54e6c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04292929292929293"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how often does (alice, was) occur and what is the relative frequency?\n",
    "print(lm.counts[['alice']]['was'])\n",
    "lm.score('was', 'alice'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "7c3dbf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04292929292929293"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NLTK Documentation:\n",
    "# Here’s how you get the score for a word given some preceding context. \n",
    "\n",
    "# For example we want to know what is the chance that “was” is preceded by “alice”.\n",
    "\n",
    "lm.score(\"was\", [\"alice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069a357",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "194495a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--', \"'\", \"''\", '</s>', 'right', 'size', 'for', 'a', 'little', ',', '``', 'it', \"'ll\", 'do', \"n't\", 'matter', 'much', 'like', 'the', 'air']\n"
     ]
    }
   ],
   "source": [
    "print(lm.generate(20, text_seed= 'alice', random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "66ffbacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--\"\\''"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now generate sentences that look much nicer. \n",
    "generate_sent(lm, 40, text_seed='alice', random_seed = 42)\n",
    "# Stops after exactly one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "1a1cb3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- i shall tell me my time together.\"'"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice', random_seed = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "d5143939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ll don't be talking about, and crept a great hurry.\""
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='martians', random_seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "233c3d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ll see anything more evidence _yet_, and tillie; for some time she appeared; to sink into a grown in things went on, ma'am, miss, just what to herself in; but she swam nearer\""
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='martians', random_seed = 547)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c5aba",
   "metadata": {},
   "source": [
    "# Part 3 - creating a tri-gram model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f7331868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 is for tri-grams!!!\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4ca24188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imported this function from nltk\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "d218b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE is the model we will use\n",
    "lm = MLE(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "712a81eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2778"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model \n",
    "# training data is the bigrams and unigrams \n",
    "# the vocab is all the sentence tokens in the corpus \n",
    "\n",
    "lm.fit(train_data, padded_sents)\n",
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "f88a971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('oh', 'dear', '!')\n"
     ]
    }
   ],
   "source": [
    "# inspect the model's vocabulary. \n",
    "# be sure that a sentence you know exists (from tokenized_text) is in the \n",
    "print(lm.vocab.lookup(tokenized_text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "e27b507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11764705882352941"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From NLTK Documentation:\n",
    "# Here’s how you get the score for a word given some preceding context. \n",
    "# For example we want to know what is the chance that “beginning” is preceded by “alice was”.\n",
    "\n",
    "print(lm.counts[['alice', 'was']]['beginning'])\n",
    "lm.score(\"beginning\", [\"alice\", \"was\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b8f53",
   "metadata": {},
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f68a593c",
   "metadata": {},
   "source": [
    "# from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "68edee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- e--e--evening, beautiful, beauti--ful soup!'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice', random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "f420793f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- evening, beautiful soup, and it stood for a minute or two she stood still where she was considering in her own child-life, and the executioner ran wildly up and down looking for eggs, as to'"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice', random_seed = 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "c7eafbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- e--e--e--e--e--e--evening, beautiful, beauti--ful soup!\"'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice', random_seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "1c597ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-- evening, beautiful, beautiful soup!'"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice', random_seed = 547)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5ebfb",
   "metadata": {},
   "source": [
    "That doesn't work!  They are all almost the same...  Maybe we need two words as a text seed for a tri-gram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "a0475043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['larger', ',', 'i', \"'ve\", 'seen', 'them', 'so', 'often', ',', 'of', 'course', '?', \"''\", '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(lm.generate(20, text_seed= 'alice was', random_seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "1d40c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'larger, i\\'ve seen them so often, of course?\"'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now generate sentences that look much nicer. \n",
    "generate_sent(lm, 40, text_seed='alice was', random_seed = 42)\n",
    "# Stops after exactly one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "9773ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', with a soldier on each side, to the mock turtle a little sharp bark just over her head!\"'"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice was', random_seed = 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "e4358a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'s argument was, that attempt proved a failure.\""
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice was', random_seed = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "01efdfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'s really dreadful,\" said the duchess sneezed occasionally; and the party.'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sent(lm, 40, text_seed='alice was', random_seed = 547)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd384c5",
   "metadata": {},
   "source": [
    "That looks better.  Still not quite sure this is right, but it was a fun experiment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
